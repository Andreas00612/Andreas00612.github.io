<!--
  IMPORTANT!

  Keep this file unchanged to use as a template for all future project pages.

  For every new project you add to your portfolio, make a copy of this file in the
  'project-pages' folder with a name related to the project.
-->

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <link rel="icon" href="../assets/images/1311.png"/>
    <title>Unemployables Portfolio</title>
    <meta name="description" content="A portfolio template for the Unemployables community.">
    <meta name="viewport" content="width=device-width, initial-scale=1"/>

    <link rel="stylesheet" href="../css/layout.css">
    <link rel="stylesheet" href="../css/typography.css">
    <link rel="stylesheet" href="../css/utilities.css">

    <script defer src="../js/script.js"></script>
</head>
<body>
<!-- NAVBAR -->
<!-- NAVBAR -->
<div class="navbar">
    <a class="nav-title-link" href="../index.html">
        <image src="/assets/icons/home.png" class="right-arrow-icon"/>
        <span class="nav-title">Home</span>
    </a>
</div>

<!-- MAIN PAGE CONTENT -->
<div id="main-content">
    <!-- PROJECT HEADER -->
    <div id="project-header">
        <div class="main-title">碩士論文-可見光到紅外線圖像轉換
        </div>
        <div class="subheader-text">《FreqShifted-Net：Frequency-Aware Axial-ShiftedNet
            in Generative Adversarial Networks for Visible-to-Infrared Image》
        </div>
        <image class="project-header-image" src="../assets/images/IR_1.png">
            <span class="subheader-text">
                    <br>上圖為我們提出的模型與SOTA所比較的結果<br>
                    A：InfraGAN  &nbsp;&nbsp;&nbsp; B：InfraGAN並改良Loss &nbsp;&nbsp;&nbsp; C：Freq-ShiftedNet並改良Loss</span>
    </div>

    <div id="project-details">
        <div class="custom-style-pro">

            <h2>論文摘要</h2>
            <div class="feature-description">
                <ul>
                    <li>
                        此論文的目標為將可見光圖像轉換為紅外線圖像，我們提出了Freq-ShiftedNet模型並使用對抗式生成網路的方式訓練，利用哈爾小波轉換有效的保留頻率資訊，透過模型轉換成紅外線圖像並同時保留有效的結構資訊，
                        與InfraGAN(SOTA)模型相比，我們的模型在SSIM指標中增加了5.4%，LPIPS指標減少了41.3%
                    </li>
                    <div class="resume-container">
                        <div class="image-s-container">
                            <img src="../assets/images/IR_header_1.png">
                        </div>
                    </div>
                </ul>
            </div>


            <hr class="separator-line">

            <h2>Freq-ShiftedNet架構圖</h2>
            <div class="resume-container">
                <div class="image-container centered-image">
                    <img src="../assets/images/IR_3.png" alt="Your Resume Image">
                </div>

            </div>
            <div class="description-container">
                <p> 整體生成器架構如圖所示，我們的生成模型包括Encoder(A)、多個Shift-ResNet Block(B)和Decoder(C)，
                    生成器的輸入為一張可見光圖像，輸入至模型後會產生出一張對應的紅外線影像。
                </p>
            </div>
            <hr class="separator-line">

            <div class="resume-container">
                <div class="image-container">
                    <img src="../assets/images/IR_Disc_1.png">
                </div>
                <div class="description-container">
                    <div class="IRheader-text">鑑別器(Discirminator)架構圖</div>
                    <p> Discriminator則由多個Encoder組成，鑑別器的輸入則為一組成對的影像，
                        包括可見光影像和其轉換後的紅外線影像。 </p>
                    <div class="image-container">
                        <img src="../assets/images/IR_Disc_2.png">
                    </div>
                </div>
            </div>
            <hr class="separator-line">

            <h2>Freq-ShiftedNet Loss Function</h2>
            <div class="resume-container">
                <div class="image-m-container centered-image">
                    <img src="../assets/images/IR_loss_lambda.png.">
                </div>

            </div>
            <div class="resume-container">
                <div class="image-m-container centered-image">
                    <img src="../assets/images/IR_loss_lambda.png.">
                </div>
            </div>

            <div class="description-container">
                <p> λ_SSIM 、λ_LPIPS 、λ_MPNCE 、λ_GP 、λ_Sobel分別代表了生成器的Loss Function的權重，</br>
                    我們將λ_SSIM 、λ_LPIPS 、λ_MPNCE 、λ_GP 設為50，而λ_Sobel設為10。
                </p>
            </div>
            <hr class="separator-line">

            <h2>KAIST資料集</h2>
            <div class="resume-container">
                <div class="image-container">
                    <img src="../assets/images/IR_dataset_table.png">
                </div>
                <div class="image-container">
                    <img src="../assets/images/IR_KAIST.png">
                </div>
            </div>
            <div class="description-container">
                <p>
                    KAIST資料集包含12個不同場景的視頻，其中有白天的校園和城市場景，以及夜晚的街道和城市場景。
                    影片皆為解析度640×512，波長範圍為7.5到13微米，且皆為每秒20幀所錄製。<br>
                    KAIST資料集所包含的不同場景和光線條件能夠提供豐富的訓練樣本，
                    這將有助於模型更好地理解並應對各種環境條件。</p>
            </div>
            <hr class="separator-line">


            <!-- Result and table -->
            <h2>KAIST資料集上各種模型的比較結果</h2>
            <div class="resume-container">
                <div class="image-container centered-image">
                    <img src="../assets/images/IR_result_1.png">
                </div>
            </div>
            <div class="resume-container">
                <div class="image-container centered-image">
                    <img src="../assets/images/IR_result_1_night.png">
                </div>
            </div>
            <div class="description-container">

                <p> 在上圖中，第一和第二列分別代表可見光影像和對應的紅外線影像。<br>
                    A：InfraGAN。<br>
                    B：具有修改Loss Function的Unet<br>
                    C：我們提出的Freq-ShiftedNet<br>
                    尤其在複雜的白天場景中，與Unet相比，Freq-ShiftedNet能夠準確地展現出結構，其SSIM與LPIPS的數據於下表所述
                </p>
                <div class="image-m-container">
                    <img src="../assets/images/IR_result_1_table.png">
                </div>
            </div>

            <hr class="separator-line">
            <!-- COnclusion -->
            <h2>結論</h2>
            <ul>
                <ul>
                    <li>提出了Freq-ShiftedNet模型並且整合了Wavelet Feature</li>
                    <li>定義了新的Loss Function並調整其對應權重</li>
                    <li>在Discriminator中使用了Projection的方法來融合Wavelet Feature</li>
                    <li>在KAIST資料集中進行測試，相比於InfraGAN<br>
                        SSIM為0.825，增加了5.4%，LPIPS為0.228，降低了41.3%。
                    </li>
                </ul>
            </ul>

        </div>
    </div>


    <div class="buttonp-container">
        <a class="button" href="Fingerprint.html">
            <image src="/assets/icons/arrow-left.png" class="right-arrow-icon"/>
            <span class="button-text">屏幕下指紋心率偵測</span>
        </a>

        <a class="button" href="RPPG.html">
            <span class="button-text">遠端即時心率測量系統</span>
            <image src="/assets/icons/arrow-right (1).png" class="right-arrow-icon"/>
        </a>
    </div>

</div>
</body>
</html>
